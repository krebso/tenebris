{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from itertools import islice\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tenebris.domain.methods.grad_cam import GradCAMMethod\n",
    "from tenebris.domain.methods.lrp import LRPEpsilonMethod\n",
    "from tenebris.domain.methods.occlusion import OcclusionMethod\n",
    "from tenebris.domain.metrics.computation_time import ComputationTimeMetric\n",
    "from tenebris.domain.metrics.deletion_check import DeletionCheck\n",
    "from tenebris.domain.metrics.preservation_check import PreservationCheck\n",
    "from tenebris.benchmark import BenchmarkService"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T17:24:37.600014Z",
     "start_time": "2023-10-22T17:24:35.758159Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST('data/', train=True, transform=transform, download=False)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "test_dataset = torchvision.datasets.MNIST('data/', train=False, transform=transform, download=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T17:24:37.650604Z",
     "start_time": "2023-10-22T17:24:37.602673Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "class MyConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 2, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(2, 6, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(96, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 96)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model = MyConvNet()\n",
    "\n",
    "model.load_state_dict(torch.load(\"mnist-classifier.pth\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T17:24:37.962537Z",
     "start_time": "2023-10-22T17:24:37.952129Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a655c3ee-5b77-4b83-a3d8-90d373d02a6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T17:24:38.568783Z",
     "start_time": "2023-10-22T17:24:38.564870Z"
    }
   },
   "outputs": [],
   "source": [
    "# Methods\n",
    "grad_cam = GradCAMMethod(model, layer_getter = lambda m: m.conv2)\n",
    "lrp_epsilon = LRPEpsilonMethod(model)\n",
    "occlusion = OcclusionMethod(model, (1, 2, 2), 2, 0)\n",
    "\n",
    "methods = [grad_cam, lrp_epsilon, occlusion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f75a6818-9272-448a-959b-31996bb307bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T17:24:39.179025Z",
     "start_time": "2023-10-22T17:24:39.172832Z"
    }
   },
   "outputs": [],
   "source": [
    "# Metrics\n",
    "\n",
    "# computation_time_metric = ComputationTimeMetric()\n",
    "deletion_check = DeletionCheck()\n",
    "preservation_check = PreservationCheck()\n",
    "\n",
    "# metrics = [computation_time_metric, deletion_check, preservation_check]\n",
    "metrics = [deletion_check, preservation_check]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7828bb-f9b4-4967-980e-a58ee25c13d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark\n",
    "\n",
    "benchmark = BenchmarkService(metrics=metrics, methods=methods)\n",
    "benchmark.run(list(islice(test_dataloader, 1000)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 600x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "from captum.attr._utils.visualization import visualize_image_attr\n",
    "\n",
    "image, label = data[6]\n",
    "attribution = lrp_epsilon.attribute(image, label)\n",
    "\n",
    "img = np.transpose(image[0].detach().numpy(), (1, 2, 0))\n",
    "attr = np.transpose(attribution[0].detach().numpy(), (1, 2, 0))\n",
    "\n",
    "_ = visualize_image_attr(attr, original_image=img, method=\"blended_heat_map\", sign=\"positive\")\n",
    "\n",
    "print(image.size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T17:17:30.692032Z",
     "start_time": "2023-10-22T17:17:30.599152Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: torch.Size([1, 1, 28, 28])\n",
      "Attribution size: torch.Size([1, 1, 28, 28])\n",
      "Binary attribution size: torch.Size([1, 1, 28, 28])\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9992], grad_fn=<MaxBackward0>),\n",
      "indices=tensor([4])) torch.return_types.max(\n",
      "values=tensor([0.9997], grad_fn=<MaxBackward0>),\n",
      "indices=tensor([4]))\n"
     ]
    }
   ],
   "source": [
    "from tenebris.domain.tensors.functions import positive_attribution_mask\n",
    "\n",
    "image, label = data[6]\n",
    "attribution = occlusion.attribute(image, label)\n",
    "binary_attribution = positive_attribution_mask(attribution)\n",
    "\n",
    "attributions_only_image = image * binary_attribution\n",
    "\n",
    "print(f\"Image size: {image.size()}\")\n",
    "print(f\"Attribution size: {attribution.size()}\")\n",
    "print(f\"Binary attribution size: {binary_attribution.size()}\")\n",
    "\n",
    "out = model(image)\n",
    "attribution_only_out = model(attributions_only_image)\n",
    "\n",
    "print(torch.max(out, dim=1), torch.max(attribution_only_out, dim=1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T17:17:40.457239Z",
     "start_time": "2023-10-22T17:17:40.382075Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "{'ComputationTimeMetric': defaultdict(list,\n             {'GuidedGradCam': [0.022142887115478516,\n               0.001081228256225586,\n               0.0009121894836425781],\n              'LRP with Epsilon rule': [0.0022919178009033203,\n               0.0013971328735351562,\n               0.0012001991271972656],\n              'Occlusion': [0.06215500831604004,\n               0.05653786659240723,\n               0.10953307151794434]}),\n 'DeletionCheck': defaultdict(list,\n             {'GuidedGradCam': [True, True, True],\n              'LRP with Epsilon rule': [True, True, False],\n              'Occlusion': [True, False, True]}),\n 'PreservationCheck': defaultdict(list,\n             {'GuidedGradCam': [False, False, False],\n              'LRP with Epsilon rule': [True, True, False],\n              'Occlusion': [True, True, True]})}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark.results()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T17:17:42.243688Z",
     "start_time": "2023-10-22T17:17:42.240340Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "{'ComputationTimeMetric': {'GuidedGradCam': 0.008045434951782227,\n  'LRP with Epsilon rule': 0.0016297499338785808,\n  'Occlusion': 0.07607531547546387},\n 'DeletionCheck': {'GuidedGradCam': 1.0,\n  'LRP with Epsilon rule': 0.6666666666666666,\n  'Occlusion': 0.6666666666666666},\n 'PreservationCheck': {'GuidedGradCam': 0.0,\n  'LRP with Epsilon rule': 0.6666666666666666,\n  'Occlusion': 1.0}}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark.reduce_results()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T17:17:44.093615Z",
     "start_time": "2023-10-22T17:17:44.089747Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
